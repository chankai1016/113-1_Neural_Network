{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f0584a",
   "metadata": {},
   "source": [
    "# Homework 11/14 (4-4 Backpropagation)\n",
    "\n",
    "This is an homework for a neural network course offered by the master's class of the Department of IEM at the NCUT in the first semester of the 2024 academic year (113-1).\n",
    "\n",
    "**Submitted by: 4B315021 詹家緯**\n",
    "\n",
    "The codes can be viewed on GitHub: [https://github.com/chankai1016/113-1_Neural_Network/](https://github.com/chankai1016/113-1_Neural_Network)\n",
    "\n",
    "## Prepare\n",
    "\n",
    "Complete the analysis of Iris Dataset using the Anaconda environment.\n",
    "\n",
    "### 1. Install Anaconda\n",
    "\n",
    "[Anaconda official website](https://www.anaconda.com/)\n",
    "\n",
    "### 2. Create a virtual environment\n",
    "\n",
    "Use Anaconda's virtual environment to isolate project dependencies.\n",
    "\n",
    "Execute command in Anaconda Prompt:\n",
    "\n",
    "```bash\n",
    "conda create -n [YOUR_ENV_NAME] python=3.9\n",
    "conda activate [YOUR_ENV_NAME]\n",
    "```\n",
    "\n",
    "*The tensorflow library requires that the python version must be 3.9 or below*\n",
    "\n",
    "### 3. Install the required packages\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge tensorflow\n",
    "conda install scikit-learn\n",
    "```\n",
    "\n",
    "### 4. Write and execute code\n",
    "\n",
    "Working in Jupyter Notebook, install Jupyter Notebook:\n",
    "\n",
    "```bash\n",
    "conda install jupyter\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c3ebd2-b469-431d-9831-ccea8866375d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 1.2348 - accuracy: 0.3148 - val_loss: 1.0825 - val_accuracy: 0.4167\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.1824 - accuracy: 0.3148 - val_loss: 1.0471 - val_accuracy: 0.4167\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.1475 - accuracy: 0.3148 - val_loss: 1.0367 - val_accuracy: 0.4167\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.1189 - accuracy: 0.3148 - val_loss: 1.0246 - val_accuracy: 0.4167\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0952 - accuracy: 0.3148 - val_loss: 1.0094 - val_accuracy: 0.4167\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0758 - accuracy: 0.3148 - val_loss: 1.0005 - val_accuracy: 0.4167\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0557 - accuracy: 0.3148 - val_loss: 0.9880 - val_accuracy: 0.4167\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0370 - accuracy: 0.3148 - val_loss: 0.9753 - val_accuracy: 0.4167\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0189 - accuracy: 0.3148 - val_loss: 0.9643 - val_accuracy: 0.4167\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.0004 - accuracy: 0.3148 - val_loss: 0.9519 - val_accuracy: 0.4167\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9861 - accuracy: 0.3148 - val_loss: 0.9369 - val_accuracy: 0.4167\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.9698 - accuracy: 0.3333 - val_loss: 0.9206 - val_accuracy: 0.4167\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.9564 - accuracy: 0.3333 - val_loss: 0.9030 - val_accuracy: 0.4167\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.9419 - accuracy: 0.4167 - val_loss: 0.8940 - val_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.9321 - accuracy: 0.5093 - val_loss: 0.8761 - val_accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.9133 - accuracy: 0.5648 - val_loss: 0.8650 - val_accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.8980 - accuracy: 0.6019 - val_loss: 0.8528 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8834 - accuracy: 0.6296 - val_loss: 0.8388 - val_accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.8676 - accuracy: 0.6296 - val_loss: 0.8234 - val_accuracy: 0.5833\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.8515 - accuracy: 0.6759 - val_loss: 0.8107 - val_accuracy: 0.5833\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.8338 - accuracy: 0.7037 - val_loss: 0.7965 - val_accuracy: 0.6667\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.8206 - accuracy: 0.6944 - val_loss: 0.7826 - val_accuracy: 0.5833\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7980 - accuracy: 0.7685 - val_loss: 0.7638 - val_accuracy: 0.9167\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7780 - accuracy: 0.8241 - val_loss: 0.7434 - val_accuracy: 0.7500\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7544 - accuracy: 0.8148 - val_loss: 0.7233 - val_accuracy: 0.9167\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7293 - accuracy: 0.8056 - val_loss: 0.6948 - val_accuracy: 0.9167\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6874 - accuracy: 0.8981 - val_loss: 0.6542 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6490 - accuracy: 0.9630 - val_loss: 0.6236 - val_accuracy: 0.9167\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.6186 - accuracy: 0.9630 - val_loss: 0.5990 - val_accuracy: 0.9167\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5939 - accuracy: 0.9259 - val_loss: 0.5779 - val_accuracy: 0.9167\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5661 - accuracy: 0.9537 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5391 - accuracy: 0.9722 - val_loss: 0.5292 - val_accuracy: 0.9167\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.4994 - accuracy: 0.9352 - val_loss: 0.4973 - val_accuracy: 0.9167\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4563 - accuracy: 0.9630 - val_loss: 0.4784 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.9722 - val_loss: 0.4504 - val_accuracy: 0.9167\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3957 - accuracy: 0.9722 - val_loss: 0.4299 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3717 - accuracy: 0.9722 - val_loss: 0.4086 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3514 - accuracy: 0.9630 - val_loss: 0.3892 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3354 - accuracy: 0.9630 - val_loss: 0.3764 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3190 - accuracy: 0.9815 - val_loss: 0.3588 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3079 - accuracy: 0.9630 - val_loss: 0.3442 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2954 - accuracy: 0.9722 - val_loss: 0.3370 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2836 - accuracy: 0.9722 - val_loss: 0.3204 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2733 - accuracy: 0.9815 - val_loss: 0.3098 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2649 - accuracy: 0.9815 - val_loss: 0.2982 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2570 - accuracy: 0.9630 - val_loss: 0.2928 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2473 - accuracy: 0.9722 - val_loss: 0.2772 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2439 - accuracy: 0.9630 - val_loss: 0.2724 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.2351 - accuracy: 0.9722 - val_loss: 0.2571 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.2274 - accuracy: 0.9815 - val_loss: 0.2522 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2474 - accuracy: 0.9667\n",
      "測試集損失: 0.24744877219200134\n",
      "測試集準確率: 0.9666666388511658\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "預測類別: setosa\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# One-Hot encode tags\n",
    "encoder = OneHotEncoder(sparse_output=False)  # Updated argument\n",
    "y_encoded = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Split the data set into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a neural network-like model\n",
    "model = Sequential([\n",
    "    Dense(10, input_dim=4, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.1)\n",
    "\n",
    "# Evaluation model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"測試集損失: {loss}\")\n",
    "print(f\"測試集準確率: {accuracy}\")\n",
    "\n",
    "# Forecasting example\n",
    "sample = np.array([[5.1, 3.5, 1.4, 0.2]])  # Iris-setosa example\n",
    "prediction = model.predict(sample)\n",
    "predicted_class = np.argmax(prediction)\n",
    "print(f\"預測類別: {iris.target_names[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded6824",
   "metadata": {},
   "source": [
    "# Hana's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2b380a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Loss: 1.0905\n",
      "Epoch 200/1000, Loss: 0.8010\n",
      "Epoch 300/1000, Loss: 0.4962\n",
      "Epoch 400/1000, Loss: 0.3953\n",
      "Epoch 500/1000, Loss: 0.3336\n",
      "Epoch 600/1000, Loss: 0.2876\n",
      "Epoch 700/1000, Loss: 0.2508\n",
      "Epoch 800/1000, Loss: 0.2203\n",
      "Epoch 900/1000, Loss: 0.1949\n",
      "Epoch 1000/1000, Loss: 0.1739\n",
      "Test Accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data  \n",
    "y = iris.target.reshape(-1, 1)  \n",
    "\n",
    "# encoder = OneHotEncoder(sparse=False) -->\n",
    "encoder = OneHotEncoder(sparse_output=False) \n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 10\n",
    "output_size = y.shape[1]\n",
    "\n",
    "np.random.seed(42)\n",
    "W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "def train(X, y, W1, b1, W2, b2, epochs=1000, lr=0.01):\n",
    "    for epoch in range(epochs):\n",
    "        # Forward propagation\n",
    "        Z1 = np.dot(X, W1) + b1\n",
    "        A1 = sigmoid(Z1)\n",
    "        Z2 = np.dot(A1, W2) + b2\n",
    "        A2 = softmax(Z2)\n",
    "       \n",
    "        loss = -np.mean(np.sum(y * np.log(A2 + 1e-8), axis=1))\n",
    "        \n",
    "        dZ2 = A2 - y\n",
    "        dW2 = np.dot(A1.T, dZ2) / X.shape[0]\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True) / X.shape[0]\n",
    "        dA1 = np.dot(dZ2, W2.T)\n",
    "        dZ1 = dA1 * sigmoid_derivative(Z1)\n",
    "        dW1 = np.dot(X.T, dZ1) / X.shape[0]\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True) / X.shape[0]\n",
    "        \n",
    "        W1 -= lr * dW1\n",
    "        b1 -= lr * db1\n",
    "        W2 -= lr * dW2\n",
    "        b2 -= lr * db2\n",
    "        \n",
    "        \n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "W1, b1, W2, b2 = train(X_train, y_train, W1, b1, W2, b2, epochs=1000, lr=0.1)\n",
    "\n",
    "def predict(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return np.argmax(A2, axis=1)\n",
    "\n",
    "y_pred = predict(X_test, W1, b1, W2, b2)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test_labels)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d2875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
